{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cloning into 'Anomaly_understanding'...\n",
      "remote: Enumerating objects: 68, done.\u001b[K\n",
      "remote: Counting objects: 100% (23/23), done.\u001b[K\n",
      "remote: Compressing objects: 100% (16/16), done.\u001b[K\n",
      "^Cceiving objects:  42% (29/68), 73.02 MiB | 2.98 MiB/s\n",
      "fetch-pack: unexpected disconnect while reading sideband packet\n",
      "[Errno 2] No such file or directory: 'Anomaly_understanding'\n",
      "/home/hvgl/edu/Anomaly/Anomaly_understanding\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/hvgl/.local/lib/python3.10/site-packages/IPython/core/magics/osm.py:393: UserWarning: This is now an optional IPython functionality, using bookmarks requires you to install the `pickleshare` library.\n",
      "  bkms = self.shell.db.get('bookmarks', {})\n"
     ]
    }
   ],
   "source": [
    "# if using colab run this\n",
    "!git clone https://github.com/HAVIGILI/Anomaly_understanding.git\n",
    "%cd Anomaly_understanding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: numpy in /home/hvgl/.local/lib/python3.10/site-packages (from -r requirements.txt (line 1)) (1.26.4)\n",
      "Requirement already satisfied: matplotlib in /home/hvgl/.local/lib/python3.10/site-packages (from -r requirements.txt (line 2)) (3.9.2)\n",
      "Requirement already satisfied: pillow in /home/hvgl/.local/lib/python3.10/site-packages (from -r requirements.txt (line 3)) (10.4.0)\n",
      "Requirement already satisfied: torch in /home/hvgl/.local/lib/python3.10/site-packages (from -r requirements.txt (line 4)) (2.4.1)\n",
      "Requirement already satisfied: torchvision in /home/hvgl/.local/lib/python3.10/site-packages (from -r requirements.txt (line 5)) (0.19.1)\n",
      "Requirement already satisfied: pytorch-ood in /home/hvgl/.local/lib/python3.10/site-packages (from -r requirements.txt (line 6)) (0.2.1)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in /home/hvgl/.local/lib/python3.10/site-packages (from matplotlib->-r requirements.txt (line 2)) (4.53.1)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in /usr/lib/python3/dist-packages (from matplotlib->-r requirements.txt (line 2)) (2.4.7)\n",
      "Requirement already satisfied: cycler>=0.10 in /home/hvgl/.local/lib/python3.10/site-packages (from matplotlib->-r requirements.txt (line 2)) (0.12.1)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in /home/hvgl/.local/lib/python3.10/site-packages (from matplotlib->-r requirements.txt (line 2)) (1.3.0)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in /home/hvgl/.local/lib/python3.10/site-packages (from matplotlib->-r requirements.txt (line 2)) (2.9.0.post0)\n",
      "Requirement already satisfied: packaging>=20.0 in /home/hvgl/.local/lib/python3.10/site-packages (from matplotlib->-r requirements.txt (line 2)) (24.1)\n",
      "Requirement already satisfied: kiwisolver>=1.3.1 in /home/hvgl/.local/lib/python3.10/site-packages (from matplotlib->-r requirements.txt (line 2)) (1.4.7)\n",
      "Requirement already satisfied: networkx in /home/hvgl/.local/lib/python3.10/site-packages (from torch->-r requirements.txt (line 4)) (3.3)\n",
      "Requirement already satisfied: jinja2 in /home/hvgl/.local/lib/python3.10/site-packages (from torch->-r requirements.txt (line 4)) (3.1.4)\n",
      "Requirement already satisfied: fsspec in /home/hvgl/.local/lib/python3.10/site-packages (from torch->-r requirements.txt (line 4)) (2024.9.0)\n",
      "Requirement already satisfied: nvidia-cusparse-cu12==12.1.0.106 in /home/hvgl/.local/lib/python3.10/site-packages (from torch->-r requirements.txt (line 4)) (12.1.0.106)\n",
      "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.1.105 in /home/hvgl/.local/lib/python3.10/site-packages (from torch->-r requirements.txt (line 4)) (12.1.105)\n",
      "Requirement already satisfied: nvidia-nccl-cu12==2.20.5 in /home/hvgl/.local/lib/python3.10/site-packages (from torch->-r requirements.txt (line 4)) (2.20.5)\n",
      "Requirement already satisfied: filelock in /home/hvgl/.local/lib/python3.10/site-packages (from torch->-r requirements.txt (line 4)) (3.16.1)\n",
      "Requirement already satisfied: sympy in /home/hvgl/.local/lib/python3.10/site-packages (from torch->-r requirements.txt (line 4)) (1.13.3)\n",
      "Requirement already satisfied: nvidia-cublas-cu12==12.1.3.1 in /home/hvgl/.local/lib/python3.10/site-packages (from torch->-r requirements.txt (line 4)) (12.1.3.1)\n",
      "Requirement already satisfied: nvidia-cudnn-cu12==9.1.0.70 in /home/hvgl/.local/lib/python3.10/site-packages (from torch->-r requirements.txt (line 4)) (9.1.0.70)\n",
      "Requirement already satisfied: nvidia-curand-cu12==10.3.2.106 in /home/hvgl/.local/lib/python3.10/site-packages (from torch->-r requirements.txt (line 4)) (10.3.2.106)\n",
      "Requirement already satisfied: nvidia-cufft-cu12==11.0.2.54 in /home/hvgl/.local/lib/python3.10/site-packages (from torch->-r requirements.txt (line 4)) (11.0.2.54)\n",
      "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.1.105 in /home/hvgl/.local/lib/python3.10/site-packages (from torch->-r requirements.txt (line 4)) (12.1.105)\n",
      "Requirement already satisfied: nvidia-cusolver-cu12==11.4.5.107 in /home/hvgl/.local/lib/python3.10/site-packages (from torch->-r requirements.txt (line 4)) (11.4.5.107)\n",
      "Requirement already satisfied: triton==3.0.0 in /home/hvgl/.local/lib/python3.10/site-packages (from torch->-r requirements.txt (line 4)) (3.0.0)\n",
      "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.1.105 in /home/hvgl/.local/lib/python3.10/site-packages (from torch->-r requirements.txt (line 4)) (12.1.105)\n",
      "Requirement already satisfied: nvidia-nvtx-cu12==12.1.105 in /home/hvgl/.local/lib/python3.10/site-packages (from torch->-r requirements.txt (line 4)) (12.1.105)\n",
      "Requirement already satisfied: typing-extensions>=4.8.0 in /home/hvgl/.local/lib/python3.10/site-packages (from torch->-r requirements.txt (line 4)) (4.12.2)\n",
      "Requirement already satisfied: nvidia-nvjitlink-cu12 in /home/hvgl/.local/lib/python3.10/site-packages (from nvidia-cusolver-cu12==11.4.5.107->torch->-r requirements.txt (line 4)) (12.6.68)\n",
      "Requirement already satisfied: scipy>=1.7.0 in /home/hvgl/.local/lib/python3.10/site-packages (from pytorch-ood->-r requirements.txt (line 6)) (1.14.1)\n",
      "Requirement already satisfied: torchmetrics>=1.0.0 in /home/hvgl/.local/lib/python3.10/site-packages (from pytorch-ood->-r requirements.txt (line 6)) (1.6.1)\n",
      "Requirement already satisfied: six>=1.5 in /home/hvgl/.local/lib/python3.10/site-packages (from python-dateutil>=2.7->matplotlib->-r requirements.txt (line 2)) (1.16.0)\n",
      "Requirement already satisfied: lightning-utilities>=0.8.0 in /home/hvgl/.local/lib/python3.10/site-packages (from torchmetrics>=1.0.0->pytorch-ood->-r requirements.txt (line 6)) (0.11.9)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /home/hvgl/.local/lib/python3.10/site-packages (from jinja2->torch->-r requirements.txt (line 4)) (2.1.5)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /home/hvgl/.local/lib/python3.10/site-packages (from sympy->torch->-r requirements.txt (line 4)) (1.3.0)\n",
      "Requirement already satisfied: setuptools in /usr/lib/python3/dist-packages (from lightning-utilities>=0.8.0->torchmetrics>=1.0.0->pytorch-ood->-r requirements.txt (line 6)) (59.6.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install -r requirements.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Name: torchvision\n",
      "Version: 0.19.1\n",
      "Summary: image and video datasets and models for torch deep learning\n",
      "Home-page: https://github.com/pytorch/vision\n",
      "Author: PyTorch Core Team\n",
      "Author-email: soumith@pytorch.org\n",
      "License: BSD\n",
      "Location: /home/hvgl/.local/lib/python3.10/site-packages\n",
      "Requires: numpy, pillow, torch\n",
      "Required-by: pytorch-ood, ultralytics\n",
      "/bin/python3\n",
      "Downloading https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz to ./data/cifar-10-python.tar.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 170498071/170498071 [00:46<00:00, 3680845.07it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting ./data/cifar-10-python.tar.gz to ./data\n",
      "Files already downloaded and verified\n",
      "length of train data 50000 length of validation data 10000 nr of classes 10\n"
     ]
    }
   ],
   "source": [
    "from torchvision import datasets\n",
    "from torchvision import transforms\n",
    "from torch.utils.data import DataLoader\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "train_transform = transforms.Compose([\n",
    "                transforms.RandomHorizontalFlip(),\n",
    "                transforms.ToTensor(),\n",
    "                transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
    "        ])\n",
    "validation_transform = transforms.Compose([\n",
    "                transforms.ToTensor(),\n",
    "                transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
    "        ])\n",
    "\n",
    "train_dataset = datasets.CIFAR10(root=\"./data\", train=True, transform=train_transform, download=True)\n",
    "validation_dataset = datasets.CIFAR10(root=\"./data\", train=False, transform=validation_transform, download=True)\n",
    "print(\"length of train data\", len(train_dataset), \"length of validation data\", len(validation_dataset), \"nr of classes\", len(train_dataset.classes))\n",
    "\n",
    "cifar_train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True)\n",
    "cifar_validation_loader = DataLoader(validation_dataset, batch_size=32, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import torchvision\n",
    "#from custommodel import CustomModel\n",
    "\n",
    "#cnn_model = CustomModel(32, len(train_dataset.classes))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#from trainer import Trainer\n",
    "\n",
    "#ModelTrainer = Trainer(cnn_model, cifar_train_loader, cifar_validation_loader, 10, 0.001)\n",
    "#ModelTrainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using downloaded and verified file: data/test_32x32.mat\n",
      "Files already downloaded and verified\n",
      "5000\n",
      "128\n",
      "tensor([-1, -1,  1,  1,  2,  3, -1,  4,  2,  9, -1, -1,  9,  4,  7,  7,  1,  6,\n",
      "         9, -1, -1, -1,  8,  8,  2, -1,  4, -1, -1, -1,  2, -1,  5,  0,  3,  0,\n",
      "        -1, -1,  7,  3, -1,  2,  0, -1, -1, -1,  2, -1, -1, -1,  5,  9,  5,  6,\n",
      "        -1,  4, -1,  9,  3,  2,  3,  5,  4,  4,  8, -1,  7,  0,  7,  2,  6, -1,\n",
      "         8,  9, -1, -1, -1, -1, -1, -1, -1,  9,  5, -1,  4,  3,  8, -1, -1, -1,\n",
      "        -1, -1,  0, -1,  6, -1,  7,  7,  4, -1,  7, -1,  8,  4, -1, -1,  5, -1,\n",
      "        -1,  5,  0,  8,  5, -1, -1,  8, -1,  4,  7,  0, -1, -1, -1,  3,  0,  6,\n",
      "        -1, -1])\n"
     ]
    }
   ],
   "source": [
    "from pytorch_ood.model import WideResNet\n",
    "from torchvision import datasets\n",
    "from pytorch_ood.utils import ToUnknown\n",
    "import random\n",
    "from torch.utils.data import Subset\n",
    "\n",
    "trans = WideResNet.transform_for(\"cifar10-pt\")\n",
    "# OOD dataset (e.g. SVHN)\n",
    "ood_dataset1 = datasets.SVHN(root=\"data\", split=\"test\", transform=trans, download=True, target_transform=ToUnknown())\n",
    "ood_dataset2 = datasets.FakeData(size=10000, image_size=(3, 32, 32), num_classes=10, transform=trans, target_transform=ToUnknown())\n",
    "ood_dataset3 = datasets.MNIST(root=\"data\", train=False, transform=trans, download=True, target_transform=ToUnknown())\n",
    "ood_dataset4 = datasets.CIFAR100(root=\"data\", train=False, transform=trans, download=True, target_transform=ToUnknown())\n",
    "ood_dataset5 = datasets.FashionMNIST(root=\"data\", train=False, transform=trans, download=True, target_transform=ToUnknown())\n",
    "ood_dataset6 = datasets.STL10(root=\"data\", split=\"test\", transform=trans, download=True, target_transform=ToUnknown())\n",
    "\n",
    "id_dataset = datasets.CIFAR10(root=\"./data\", train=False, transform=validation_transform, download=True)\n",
    "\n",
    "ood_datasets = [ood_dataset1, ood_dataset2, ood_dataset3, ood_dataset4, ood_dataset5, ood_dataset6]  # Add all your OOD datasets here\n",
    "\n",
    "desired_size = 5000  # Set your desired size\n",
    "\n",
    "for i, ood_dataset in enumerate(ood_datasets):\n",
    "    all_indices = list(range(len(ood_dataset)))\n",
    "    random.shuffle(all_indices)\n",
    "    subset_indices = all_indices[:desired_size]\n",
    "    subset = Subset(ood_dataset, subset_indices)\n",
    "    ood_datasets[i] = subset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from anomaly_detector import AnomalyDetector\n",
    "\n",
    "model = WideResNet(num_classes=10, pretrained=\"cifar10-pt\").to(device).eval()\n",
    "calibration_dataset = train_dataset\n",
    "id_test_dataset = id_dataset\n",
    "\n",
    "for i, ood_dataset in enumerate(ood_datasets):\n",
    "    print(\"OOD dataset\", i)\n",
    "    ood_test_dataset = ood_dataset\n",
    "    detector = AnomalyDetector(model, calibration_dataset, id_test_dataset, ood_test_dataset, device=device)\n",
    "\n",
    "    layers = [model.conv1, model.block1, model.block2, model.block3, nn.Sequential(model.bn1, model.relu)]\n",
    "    head = nn.Sequential(nn.AdaptiveAvgPool2d(1), nn.Flatten(), model.fc)\n",
    "\n",
    "    print(\"multimahalanobis distance results:\")\n",
    "    detector.multimahalanobis(layers, True)\n",
    "\n",
    "    print(\"mahalanobis distance results:\")\n",
    "    detector.mahalanobis(True)\n",
    "\n",
    "    print(\"openmax results:\")\n",
    "    detector.openmax(True)\n",
    "\n",
    "    print(\"gram results:\")\n",
    "    detector.gram(head, layers, 10, [1, 2, 3, 4, 5], True)\n",
    "\n",
    "    print(\"maxsoftmax results:\")\n",
    "    detector.maxsoftmax(True)\n",
    "\n",
    "    print(\"mcd results:\")\n",
    "    detector.mcd(30, True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Image downloaded: plane.jpg\n",
      "Preprocessed image tensor: torch.Size([1, 3, 32, 32])\n",
      "Predicted class: airplane\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "\n",
    "# URL of the plane image\n",
    "url = \"https://th.bing.com/th/id/R.21621d8860f8aa6040a48c551a930de2?rik=3uoSLAbD6Voriw&riu=http%3a%2f%2fjamsdesignsinc.com%2fwp-content%2fuploads%2f2018%2f06%2fAirplane_01-square-1024x1024.jpg&ehk=n5hvZiqC3bgBZZ3z9tNUuH%2fBdsLAQFf%2bb2atiLN4Vx0%3d&risl=&pid=ImgRaw&r=0\"\n",
    "\n",
    "# Download the image\n",
    "response = requests.get(url)\n",
    "if response.status_code == 200:\n",
    "    with open(\"plane.jpg\", \"wb\") as f:\n",
    "        f.write(response.content)\n",
    "    print(\"Image downloaded: plane.jpg\")\n",
    "else:\n",
    "    print(\"Failed to download image\")\n",
    "\n",
    "from PIL import Image\n",
    "from torchvision import transforms\n",
    "\n",
    "# Load the downloaded image\n",
    "img = Image.open(\"plane.jpg\")\n",
    "\n",
    "# Define CIFAR-10 preprocessing: resize, convert to tensor, and normalize\n",
    "preprocess = transforms.Compose([\n",
    "    transforms.Resize((32, 32)),  # Resize to 32x32 pixels\n",
    "    transforms.ToTensor(),       # Convert to tensor\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])  # Normalize (CIFAR-10 stats)\n",
    "])\n",
    "\n",
    "# Preprocess the image\n",
    "input_tensor = preprocess(img).unsqueeze(0)  # Add batch dimension\n",
    "print(\"Preprocessed image tensor:\", input_tensor.shape)\n",
    "\n",
    "# Load your trained model\n",
    "cnn_model.eval()  # Ensure the model is in evaluation mode\n",
    "\n",
    "# Pass the image through the model\n",
    "with torch.no_grad():\n",
    "    output = cnn_model(input_tensor.to(device))\n",
    "    predicted_class = output.argmax(dim=1).item()\n",
    "\n",
    "# CIFAR-10 class labels\n",
    "class_labels = ['airplane', 'automobile', 'bird', 'cat', 'deer', 'dog', 'frog', 'horse', 'ship', 'truck']\n",
    "\n",
    "# Print the prediction\n",
    "print(\"Predicted class:\", class_labels[predicted_class])\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
